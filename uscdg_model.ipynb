{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_data():\n",
    "    path = \"./dataset/train_32x32.mat\"\n",
    "    data = loadmat(path)\n",
    "    training_x = data['X']\n",
    "    training_y = data['y']\n",
    "    \n",
    "    transposed_X_train = np.transpose(training_x, (3, 0, 1, 2))\n",
    "    #print(\"transposed_X_train's shape : \",np.shape(transposed_X_train))\n",
    "    return transposed_X_train, training_y\n",
    "\n",
    "def make_batch(data, batch_size):\n",
    "    data_length = len(data)\n",
    "    #print(\"data_length :\", data_length)\n",
    "    index = np.arange(0, data_length)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    #print(\"index's shape : \", np.shape(index))\n",
    "    #print(\"index : \", index)\n",
    "    shuffled_data = [data[i] for i in index]\n",
    "    \n",
    "    return shuffled_data\n",
    "\n",
    "def load_mnist_batch_data(batch_size):\n",
    "    mnist_x_batch, mnist_y_batch = mnist.train.next_batch(batch_size)\n",
    "    reshaped_x_batch = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        reshaped_x_batch.append(np.reshape(mnist_x_batch[i], (28, 28)))\n",
    "    resized_x_batch = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        resized_x_batch.append(cv2.resize(reshaped_x_batch[i], (32, 32)))\n",
    "\n",
    "    output = np.reshape(resized_x_batch, (batch_size, 32, 32, 1))\n",
    "    return output\n",
    "\n",
    "def data_normalize(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    #denominator = 255\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    \n",
    "    return (numerator * (denominator))\n",
    "\n",
    "\n",
    "def color_img_normalize(data):\n",
    "    batch_size = len(data)\n",
    "    row_size = len(data[0])\n",
    "    col_size = len(data[0][0])\n",
    "    channel_size = 3\n",
    "    tmp = np.zeros((batch_size, row_size, col_size, channel_size), dtype=np.float32)\n",
    "    for i in range(batch_size):\n",
    "        tmp[i] = data[i]/255.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, batch_size, d_lr, g_lr, epochs):\n",
    "        self.batch_size = batch_size\n",
    "        self.d_lr = d_lr\n",
    "        self.g_lr = g_lr\n",
    "        self.epochs = epochs\n",
    "        self.img_width = 32\n",
    "        self.img_height = 32\n",
    "        self.img_channel = 3\n",
    "        self.mnist_channel = 1\n",
    "        self.src_domain_img = tf.placeholder(dtype = tf.float32, shape = [None, 32, 32, 3])\n",
    "        self.trg_domain_img = tf.placeholder(dtype = tf.float32, shape = [None, 32, 32, 1])\n",
    "        self.model()\n",
    "        \n",
    "    def feature_extractor(self, _input):\n",
    "        if(np.shape(_input)[3] == 1):\n",
    "            _input = tf.image.grayscale_to_rgb(_input)\n",
    "        with tf.variable_scope(\"feature_extractor\", reuse = tf.AUTO_REUSE):\n",
    "            net = tf.layers.conv2d(inputs = _input, filters = 64, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 128, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 256, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d(inputs = net, filters = 512, kernel_size = [3, 3], padding = \"SAME\", strides = (1, 1), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d(inputs = net, filters = 256, kernel_size = [3, 3], padding = \"SAME\", strides = (1, 1), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 128, kernel_size = [4, 4], padding = \"VALID\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.tanh(net)\n",
    "\n",
    "            return net\n",
    "        \n",
    "    def discriminator(self, _input):\n",
    "        with tf.variable_scope(\"discriminator\", reuse = tf.AUTO_REUSE):\n",
    "            net = tf.layers.conv2d(inputs = _input, filters = 128, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 256, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 512, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(inputs = net, filters = 1, kernel_size = [4, 4], padding = \"VALID\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.flatten(net)\n",
    "            return tf.nn.sigmoid(net), net\n",
    "    \n",
    "    def generator(self, _input):\n",
    "        with tf.variable_scope(\"generator\", reuse = tf.AUTO_REUSE):\n",
    "            net = tf.layers.conv2d_transpose(inputs = _input, filters = 512, kernel_size = [4, 4], padding = \"VALID\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d_transpose(inputs = net, filters = 512, kernel_size = [3, 3], padding = \"SAME\", strides = (1, 1), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d_transpose(inputs = net, filters = 512, kernel_size = [3, 3], padding = \"SAME\", strides = (1, 1), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "\n",
    "            net = tf.layers.conv2d_transpose(inputs = net, filters = 256, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d_transpose(inputs = net, filters = 128, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.layers.batch_normalization(net, training=True, momentum=0.95)\n",
    "            net = tf.nn.relu(net)\n",
    "            \n",
    "            net = tf.layers.conv2d_transpose(inputs = net, filters = self.mnist_channel, kernel_size = [3, 3], padding = \"SAME\", strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            net = tf.nn.tanh(net)\n",
    "            \n",
    "            return net\n",
    "    \n",
    "    def model(self):\n",
    "        #input -> self.src_domain_img, self.trg_domain_img\n",
    "        #source_domain 입장\n",
    "        self.src_fx = self.feature_extractor(self.src_domain_img)\n",
    "        self.src_gfx = self.generator(self.src_fx)\n",
    "        self.src_fgfx = self.feature_extractor(self.src_gfx)\n",
    "        self.D1, self.D1_logits = self.discriminator(self.src_gfx)\n",
    "        \n",
    "        #target_domain 입장\n",
    "        self.trg_fx = self.feature_extractor(self.trg_domain_img)\n",
    "        self.trg_gfx = self.generator(self.trg_fx)\n",
    "        self.D2, self.D2_logits = self.discriminator(self.trg_gfx)\n",
    "        \n",
    "        self.D3, self.D3_logits = self.discriminator(self.trg_domain_img)\n",
    "        \n",
    "        self.L_D1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D1_logits, labels=tf.zeros_like(self.D1_logits)))\n",
    "        self.L_D2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D2_logits, labels=tf.zeros_like(self.D2_logits)))\n",
    "        self.L_D3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D3_logits, labels=tf.ones_like(self.D3_logits)))\n",
    "        \n",
    "        self.Loss_D = self.L_D1 + self.L_D2 + self.L_D3\n",
    "        \n",
    "        self.L_G1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D1_logits, labels = tf.ones_like(self.D1_logits)))\n",
    "        self.L_G2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.D2_logits, labels = tf.ones_like(self.D2_logits)))\n",
    "        \n",
    "        self.L_Gang = self.L_G1 + self.L_G2\n",
    "        \n",
    "        self.L_const = tf.reduce_mean(tf.square(self.src_fx - self.src_fgfx))*15\n",
    "        self.L_tid = tf.reduce_mean(tf.square(self.trg_domain_img - self.trg_gfx))\n",
    "        \n",
    "        self.L_tv = tf.reduce_mean(tf.squared_difference(self.trg_gfx[:,1:,:,:], self.trg_gfx[:,:-1,:,:])) + tf.reduce_mean(tf.squared_difference(self.trg_gfx[:,:,1:,:], self.trg_gfx[:,:,:-1,:]))+ \\\n",
    "                    tf.reduce_mean(tf.squared_difference(self.src_gfx[:,1:,:,:], self.src_gfx[:,:-1,:,:])) + tf.reduce_mean(tf.squared_difference(self.src_gfx[:,:,1:,:], self.src_gfx[:,:,:-1,:]))\n",
    "        \n",
    "        alpha = 15\n",
    "        beta = 15\n",
    "        gamma = 1\n",
    "        self.Loss_G = self.L_Gang + alpha*self.L_const + beta*self.L_tid + gamma*self.L_tv\n",
    "        \n",
    "    def train(self):\n",
    "        #학습할 변수 load\n",
    "        trainable_variables = tf.trainable_variables()\n",
    "        self.d_var = [var for var in trainable_variables if 'discriminator' in var.name]\n",
    "        self.g_var = [var for var in trainable_variables if 'generator' in var.name]\n",
    "        self.g_var.extend([var for var in trainable_variables if 'feature_extractor' in var.name])\n",
    "        \n",
    "        #model load\n",
    "        \n",
    "        #starter_learning_rate_g = self.g_lr\n",
    "        #starter_learning_rate_d = self.d_lr\n",
    "        #global_step = tf.Variable(0, trainable=False)\n",
    "        #self.g_lr_dacay = tf.train.exponential_decay(starter_learning_rate_g, global_step, 900, 0.6, staircase=True)#900 step마다 learning rate 감소\n",
    "        #self.d_lr_dacay = tf.train.exponential_decay(starter_learning_rate_d, global_step, 900, 0.6, staircase=True)#900 step마다 learning rate 감소\n",
    "        \n",
    "        \n",
    "        self.optimize_d = tf.train.AdamOptimizer(learning_rate = self.d_lr).minimize(self.Loss_D, var_list = self.d_var)#, global_step = global_step)\n",
    "        self.optimize_g = tf.train.AdamOptimizer(learning_rate = self.g_lr).minimize(self.Loss_G, var_list = self.g_var)#, global_step = global_step)\n",
    "        \n",
    "        #data load\n",
    "        source_x, _ = load_svhn_data()\n",
    "        #source_x = color_img_normalize(source_x)\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            wirter = tf.summary.FileWriter('./mygraph',sess.graph)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            batch_size = self.batch_size\n",
    "            num_of_data = 72256#svhn data size\n",
    "            total_batch = int(num_of_data / batch_size)\n",
    "            \n",
    "            #weight load\n",
    "            SAVE_PATH = \"./Weight/Weight.ckpt\"\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            try:\n",
    "                print(\"Existed Weight.ckpt load\")\n",
    "                saver.restore(sess, SAVE_PATH)\n",
    "            except:\n",
    "                print(\"No Weight exist\")\n",
    "                print(\"Start Training with newly made Weight.ckpt\")\n",
    "            \n",
    "            print(\"train start\")\n",
    "            loss_gen_list = []\n",
    "            loss_dis_list = []\n",
    "            loss_fea_list = []\n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                batch_loss_g = []\n",
    "                batch_loss_d = []\n",
    "                print(\"---------------------------------------------------------\")\n",
    "                #print(\"learning rate : \", self.lr.eval())\n",
    "                for iteration in range(total_batch):#(total_batch):\n",
    "                    #data load\n",
    "                    #print(\"1\")\n",
    "                    batch_source_x = make_batch(source_x, self.batch_size)\n",
    "                    #print(\"2\")\n",
    "                    batch_source_x = color_img_normalize(batch_source_x)\n",
    "                    #print(\"3\")\n",
    "                    batch_target_x = load_mnist_batch_data(self.batch_size)\n",
    "                    #print(\"4\")\n",
    "                    #batch_target_x = data_normalize(batch_target_x)\n",
    "                    \n",
    "                    #train start\n",
    "                    \n",
    "                    _, discriminator_loss = sess.run([self.optimize_d, self.Loss_D], feed_dict = {self.src_domain_img : batch_source_x, self.trg_domain_img : batch_target_x})\n",
    "                    _, generator_loss = sess.run([self.optimize_g, self.Loss_G], feed_dict = {self.src_domain_img : batch_source_x, self.trg_domain_img : batch_target_x})\n",
    "                    #_, feature_extractor_loss = sess.run([self.optimize_f, self.loss_f], feed_dict = {self.source_domain_img : source_train_data, self.target_domain_img : target_train_data})\n",
    "                    #print(discriminator_loss, generator_loss)\n",
    "                    loss_dis_list.append(discriminator_loss)\n",
    "                    loss_gen_list.append(generator_loss)\n",
    "                    #loss_fea_list.append(feature_extractor_loss)\n",
    "\n",
    "                output = sess.run(self.src_gfx, feed_dict = {self.src_domain_img : batch_source_x})\n",
    "                \n",
    "                dis_loss_sum = sum(loss_dis_list[-batch_size:])\n",
    "                gen_loss_sum = sum(loss_gen_list[-batch_size:])                \n",
    "                \n",
    "                print(epoch+1, \"epoch average loss_d : \", dis_loss_sum/batch_size)                \n",
    "                print(epoch+1, \"epoch average loss_g : \", gen_loss_sum/batch_size)\n",
    "                \n",
    "                saver.save(sess, SAVE_PATH)\n",
    "                for i in range(self.batch_size):\n",
    "                    for row in range(self.img_width):\n",
    "                        for col in range(self.img_height):\n",
    "                            for channel in range(self.mnist_channel):\n",
    "                                output[i][row][col][channel] = int(output[i][row][col][channel])\n",
    "                output = np.reshape(output, (self.batch_size, self.img_width, self.img_height))\n",
    "                plt.imshow(output[0])\n",
    "                plt.show()\n",
    "                if(epoch%1== 0):\n",
    "\n",
    "                    fig, ax = plt.subplots(1, self.batch_size, figsize=(self.batch_size, 2))\n",
    "                    for i in range(self.batch_size):\n",
    "                        ax[i].set_axis_off()\n",
    "                        ax[i].imshow(batch_source_x[i])\n",
    "\n",
    "                    fig2, ax2 = plt.subplots(1, self.batch_size, figsize=(self.batch_size, 2))\n",
    "                    for i in range(self.batch_size):\n",
    "                        ax2[i].set_axis_off()\n",
    "                        ax2[i].imshow(output[i])\n",
    "                    plt.show()\n",
    "\n",
    "                plt.plot(loss_dis_list)\n",
    "                plt.title(\"discriminator's loss\")\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(loss_gen_list)\n",
    "                plt.title(\"generator's loss\")\n",
    "                plt.show()\n",
    "                \n",
    "                batch_source_x, batch_target_x, d_src_gfx, d_trg_gfx, d_trg_img, output0, output1 = self.test()\n",
    "                index = 0\n",
    "                plt.imshow(batch_source_x[index])\n",
    "                plt.show()\n",
    "                \n",
    "                batch_target_x = np.reshape(batch_target_x, (self.batch_size, 32, 32))\n",
    "                plt.imshow(batch_target_x[index])\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"source domain generate\")\n",
    "                tmp = np.reshape(output0, (self.batch_size, 32, 32))\n",
    "                for i in range(4):\n",
    "                    plt.imshow(tmp[i])\n",
    "                    plt.show()\n",
    "                \n",
    "                print(\"target domain generate\")\n",
    "                tmp = np.reshape(output1, (self.batch_size, 32, 32))\n",
    "                for i in range(4):\n",
    "                    plt.imshow(tmp[i])\n",
    "                    plt.show()\n",
    "        \n",
    "    def test(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #weight load\n",
    "            SAVE_PATH = \"./Weight/Weight.ckpt\"\n",
    "            saver = tf.train.Saver()\n",
    "            try:\n",
    "                print(\"Existed Weight.ckpt load\")\n",
    "                saver.restore(sess, SAVE_PATH)\n",
    "            except:\n",
    "                print(\"No Weight exist\")\n",
    "                print(\"Start Training with newly made Weight.ckpt\")\n",
    "\n",
    "            #data load\n",
    "            source_x, _ = load_svhn_data()\n",
    "            batch_source_x = make_batch(source_x, self.batch_size)\n",
    "\n",
    "            batch_target_x = load_mnist_batch_data(self.batch_size)\n",
    "            batch_target_x = data_normalize(batch_target_x)\n",
    "\n",
    "            #discriminator 성능 test\n",
    "            d_src_gfx = sess.run(self.D1, feed_dict = {self.src_domain_img : batch_source_x})\n",
    "            d_trg_gfx = sess.run(self.D2, feed_dict = {self.trg_domain_img : batch_target_x})\n",
    "            d_trg_img = sess.run(self.D3, feed_dict = {self.trg_domain_img : batch_target_x})\n",
    "\n",
    "            \n",
    "            #generator 성능 test\n",
    "            output0 = sess.run(self.src_gfx, feed_dict = {self.src_domain_img : batch_source_x})\n",
    "            \n",
    "            output1 = sess.run(self.trg_gfx, feed_dict = {self.trg_domain_img : batch_target_x})\n",
    "            \n",
    "            \n",
    "            #for i in range(self.batch_size):\n",
    "            #    for row in range(self.img_width):\n",
    "            #        for col in range(self.img_height):\n",
    "            #           for channel in range(self.mnist_channel):\n",
    "            #               output[i][row][col][channel] = (output[i][row][col][channel])\n",
    "                            \n",
    "            return batch_source_x, batch_target_x, d_src_gfx, d_trg_gfx, d_trg_img, output0, output1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
